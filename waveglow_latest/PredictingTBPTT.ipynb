{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_lengths = tensor([800, 732, 658, 147, 329]) self.len = 0 processed = 0\n",
      "batch_lengths = tensor([700, 632, 558,  47, 229]) self.len = 1 processed = 0\n",
      "batch_lengths = tensor([600, 532, 458, 129,  62]) self.len = 2 processed = 1\n",
      "batch_lengths = tensor([500, 432, 358,  29, 261]) self.len = 3 processed = 2\n",
      "batch_lengths = tensor([400, 332, 258, 161]) self.len = 4 processed = 3\n",
      "len = 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "truncated_length = 100\n",
    "\n",
    "lengths = torch.tensor([800,732,658,147,329,76,62,261])\n",
    "batch = []\n",
    "len = 0\n",
    "processed = 0\n",
    "batch_lengths = lengths[:batch_size] # starting batch\n",
    "while True:\n",
    "    batch_lengths = torch.cat((batch_lengths, lengths[processed+batch_size:processed+batch_size+(batch_size - batch_lengths.shape[0])]), 0)\n",
    "    print(\"batch_lengths =\", batch_lengths, \"self.len =\", len, \"processed =\",processed)\n",
    "    if (batch_lengths.shape[0] < batch_size):\n",
    "        break\n",
    "    batch_lengths = (batch_lengths-truncated_length)[batch_lengths-truncated_length>0] # theoretical length of the elements in the next batch that came from this batch.\n",
    "    processed+=batch_size-batch_lengths.shape[0]\n",
    "    len += 1\n",
    "print(\"len =\",len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce index array containing filelist index and start frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed = 0 batch_indexes = tensor([0, 1, 2, 3, 4]) batch_lengths = tensor([ 80, 732, 358, 147, 329])\n",
      "----------------------\n",
      "processed = 1 batch_indexes = tensor([0, 1, 2, 3, 4]) batch_lengths = tensor([ 62, 632, 258,  47, 229])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [0] cannot be broadcast to indexing result of shape [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d5e1a11ca5e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprocessed\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_lengths\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mlen\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mbatch_lengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_lengths\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_lengths\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [0] cannot be broadcast to indexing result of shape [2]"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "truncated_length = 100\n",
    "\n",
    "dataloader_indexes = []\n",
    "\"\"\"[\n",
    "    [0, 0], # [index, index_frame_offset]\n",
    "    [1, 0],\n",
    "    [2, 0],\n",
    "    [3, 0],\n",
    "    [4, 0], # end of iter 1\n",
    "    [5, 0], # start of iter 2\n",
    "    [1, 100],\n",
    "    [2, 100],\n",
    "    [3, 100],\n",
    "    [4, 100], # end of iter 2\n",
    "]\"\"\"\n",
    "\n",
    "lengths = torch.tensor([80,732,358,147,329,76,62,261])\n",
    "batch = []\n",
    "len = 0\n",
    "processed = 0\n",
    "batch_lengths = lengths[:batch_size] # starting batch\n",
    "batch_indexes = torch.arange(batch_size)\n",
    "while True:\n",
    "    print(\"processed =\", processed, \"batch_indexes =\", batch_indexes, \"batch_lengths =\", batch_lengths)\n",
    "    batch_lengths = batch_lengths-truncated_length\n",
    "    processed+=(batch_lengths<1).sum().item()\n",
    "    batch_indexes[batch_lengths<1] = lengths[processed+batch_size:processed+batch_size]\n",
    "    len += 1\n",
    "    batch_lengths[batch_lengths<1] = lengths[processed+batch_size:processed+batch_size+(batch_lengths<1).sum().item()]\n",
    "    print(\"----------------------\")\n",
    "\n",
    "    if len > 20: break\n",
    "print(\"len =\",len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [80 , 160, 240, 320, 400] # [ 0, 1, 2, 3, 4] # start\n",
    "# [80 , 160, 240, 320, 400] # [ 0, 1, 2, 3, 4] # start\n",
    "# [-20,  60, 140, 220, 300] # [ 0, 1, 2, 3, 4] # truncate\n",
    "\n",
    "# [400,  60, 140, 220, 300] # [ 5, 1, 2, 3, 4] # replace\n",
    "# [400,  60, 140, 220, 300] # [ 5, 1, 2, 3, 4] # start\n",
    "# [300, -40,  40, 120, 200] # [ 5, 1, 2, 3, 4] # truncate\n",
    "\n",
    "# [300, 480,  40, 120, 200] # [ 5, 6, 2, 3, 4] # replace\n",
    "# [300, 480,  40, 120, 200] # [ 5, 6, 2, 3, 4] # start\n",
    "# [200, 380, -60,  20, 100] # [ 5, 6, 2, 3, 4] # truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([274, 453, 186, 498, 202, 283,  94, 697,  98, 373, 673, 561, 363, 154,\n",
      "        190])\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "tensor([274, 453, 186, 498, 202, 283])\n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "tensor([174, 353,  86, 398, 102, 183])\n",
      "---------------------\n",
      "tensor([174, 353,  86, 398, 102, 183])\n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "tensor([ 74, 253, -14, 298,   2,  83])\n",
      "---------------------\n",
      "tensor([ 74, 253,  94, 298,   2,  83])\n",
      "tensor([0, 1, 6, 3, 4, 5])\n",
      "tensor([-26, 153,  -6, 198, -98, -17])\n",
      "---------------------\n",
      "tensor([697, 153,  98, 198, 373, 673])\n",
      "tensor([ 7,  1,  8,  3,  9, 10])\n",
      "tensor([597,  53,  -2,  98, 273, 573])\n",
      "---------------------\n",
      "tensor([597,  53, 561,  98, 273, 573])\n",
      "tensor([ 7,  1, 11,  3,  9, 10])\n",
      "tensor([497, -47, 461,  -2, 173, 473])\n",
      "---------------------\n",
      "tensor([497, 363, 461, 154, 173, 473])\n",
      "tensor([ 7, 12, 11, 13,  9, 10])\n",
      "tensor([397, 263, 361,  54,  73, 373])\n",
      "---------------------\n",
      "[(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0)]\n",
      "[(0, 100.0), (1, 100.0), (2, 100.0), (3, 100.0), (4, 100.0), (5, 100.0)]\n",
      "[(0, 200.0), (1, 200.0), (6, 0.0), (3, 200.0), (4, 200.0), (5, 200.0)]\n",
      "[(7, 0.0), (1, 300.0), (8, 0.0), (3, 300.0), (9, 0.0), (10, 0.0)]\n",
      "[(7, 100.0), (1, 400.0), (11, 0.0), (3, 400.0), (9, 100.0), (10, 100.0)]\n",
      "[(7, 200.0), (12, 0.0), (11, 100.0), (13, 0.0), (9, 200.0), (10, 200.0)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "n_gpus = 1\n",
    "total_batch_size = batch_size * n_gpus # number of audio files being processed simultainously\n",
    "truncated_lengths = 100 # frames\n",
    "\n",
    "dataloader_indexes = []\n",
    "\"\"\"[\n",
    "    [0, 0], # [index, index_frame_offset]\n",
    "    [1, 0],\n",
    "    [2, 0],\n",
    "    [3, 0],\n",
    "    [4, 0], # end of iter 1\n",
    "    [5, 0], # start of iter 2\n",
    "    [1, 100],\n",
    "    [2, 100],\n",
    "    [3, 100],\n",
    "    [4, 100], # end of iter 2\n",
    "]\"\"\"\n",
    "\n",
    "#audio_lengths = (torch.arange(100)+1)*80\n",
    "audio_lengths = torch.randint(80,800,(15,))\n",
    "print(audio_lengths)\n",
    "\n",
    "batch_remaining_lengths = audio_lengths[:total_batch_size]\n",
    "batch_frame_offset = torch.zeros(total_batch_size)\n",
    "batch_indexes = torch.tensor(list(range(total_batch_size)))\n",
    "processed = 0\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "while audio_lengths.shape[0]+1>processed+total_batch_size+currently_empty_lengths:\n",
    "    # replace empty lengths\n",
    "    currently_empty_lengths = (batch_remaining_lengths<1).sum().item()\n",
    "    # update batch_indexes\n",
    "    batch_indexes[batch_remaining_lengths<1] = torch.arange(processed+total_batch_size, processed+total_batch_size+currently_empty_lengths)\n",
    "    # update batch_frame_offset\n",
    "    batch_frame_offset[batch_remaining_lengths<1] = 0\n",
    "    # update batch_remaining_lengths\n",
    "    batch_remaining_lengths[batch_remaining_lengths<1] = audio_lengths[processed+total_batch_size:processed+total_batch_size+currently_empty_lengths]\n",
    "    \n",
    "    # update how many audiofiles have been fully used\n",
    "    processed+=currently_empty_lengths\n",
    "    \n",
    "    dataloader_indexes.append(list(zip(batch_indexes.numpy(), batch_frame_offset.numpy())))\n",
    "    print(batch_remaining_lengths, batch_indexes, sep=\"\\n\")\n",
    "    \n",
    "    batch_remaining_lengths = batch_remaining_lengths - truncated_lengths # truncate batch\n",
    "    batch_frame_offset = batch_frame_offset + truncated_lengths\n",
    "    print(batch_remaining_lengths, \"---------------------\", sep=\"\\n\")\n",
    "\n",
    "print(\"\\n\".join([str(x) for x in dataloader_indexes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0101, 0.2086, 0.6089, 0.9950, 0.6090, 0.9500])\n",
      "tensor([  5.5931, 115.7942, 337.9148, 552.2272, 338.0084, 527.2679])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(6)\n",
    "print(x)\n",
    "x*=555\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.88 ns ± 0.0437 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "if 1:\n",
    "    pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
