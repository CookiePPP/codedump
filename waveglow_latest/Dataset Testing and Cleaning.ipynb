{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cleaning/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: operation does not have an identity.\n",
      "Text: ['---'] Failed to process.\n"
     ]
    }
   ],
   "source": [
    "print(\"Exception: operation does not have an identity.\")\n",
    "print(\"Text: ['---'] Failed to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from random import shuffle\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Functions\n",
    "def force_move_dir(root_src_dir, root_dst_dir):\n",
    "    for src_dir, dirs, files in tqdm(os.walk(root_src_dir), smoothing=0):\n",
    "        dst_dir = src_dir.replace(root_src_dir, root_dst_dir, 1)\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "        for file_ in files:\n",
    "            src_file = os.path.join(src_dir, file_)\n",
    "            dst_file = os.path.join(dst_dir, file_)\n",
    "            if os.path.exists(dst_file):\n",
    "                # in case of the src and dst are the same file\n",
    "                if os.path.samefile(src_file, dst_file):\n",
    "                    continue\n",
    "                os.remove(dst_file)\n",
    "            shutil.move(src_file, dst_dir)\n",
    "\n",
    "\n",
    "def reset_directory_structure(inputpath, outputpath, verbose=True):\n",
    "    \"\"\"delete outputpath, copy folder structure of inputpath to outputpath but no files\"\"\"\n",
    "    assert inputpath != outputpath\n",
    "    import shutil\n",
    "    if os.path.exists(outputpath):\n",
    "        if verbose:\n",
    "            print(\"Resetting \",outputpath)\n",
    "        shutil.rmtree(outputpath)\n",
    "    def ig_f(dir, files):\n",
    "        return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n",
    "    shutil.copytree(inputpath, outputpath, ignore=ig_f)\n",
    "\n",
    "\n",
    "def even_split(a, n):\n",
    "    \"\"\"split array into n seperate evenly sized chunks\"\"\"\n",
    "    n = min(n, len(a)) # if less elements in array than chunks to output, change chunks to array length\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    # list(chunks([0,1,2,3,4,5,6,7,8,9],2)) -> [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "def get_arpadict(dictionary_path):\n",
    "    print(\"Running, Please wait...\")\n",
    "    thisdict = {}\n",
    "    for line in reversed((open(dictionary_path, \"r\").read()).splitlines()):\n",
    "        thisdict[unidecode((line.split(\" \",1))[0])] = unidecode((line.split(\" \",1))[1].strip())\n",
    "    print(\"Dictionary Ready.\")\n",
    "    return thisdict\n",
    "\n",
    "\n",
    "def concat_text(filenames, outpath):\n",
    "    with open(outpath, 'w') as outfile:\n",
    "        nan = 0\n",
    "        for fname in filenames:\n",
    "            if nan == 1: outfile.write(\"\\n\") # add newlines (\\n) between each file\n",
    "            else: nan = 1\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "\n",
    "\n",
    "def arpabet(input_path, output_path, start_tokens=True, encoding=\"utf-8\"):\n",
    "    errored_words = \"\"\n",
    "    sym = list(r\"\"\"!?,.;:␤\"'#-_☺☻♥♦♣♠•◘○◙♂♀♪♫☼►◄↕‼¶§▬↨↑↓→←∟↔▲\"\"\") # ␤ = new line\n",
    "    output_string = \"\"\n",
    "    for line in ((open(input_path, \"r\").read()).splitlines()):\n",
    "        out = ''\n",
    "        for word_ in (line.split(\"|\")[1]).split(\" \"):\n",
    "            word=word_; end_chars = ''; start_chars = ''\n",
    "            while any(elem in word for elem in sym) and len(word) > 1:\n",
    "                if word[-1] in sym: end_chars = word[-1] + end_chars; word = word[:-1]\n",
    "                elif word[0] in sym: start_chars = start_chars + word[0]; word = word[1:]\n",
    "                else: break\n",
    "            try: word_arpa = thisdict[word.upper()]\n",
    "            except: word_arpa = ''\n",
    "            if len(word_arpa)!=0: word = \"{\" + str(word_arpa) + \"}\"\n",
    "            out = (out + \" \" + start_chars + word + end_chars).strip()\n",
    "        output_string =  output_string + line.split(\"|\")[0] + \"|\" + out + \"␤|\" + line.split(\"|\")[2] + \"\\n\"\n",
    "    text_file = open(output_path, \"w\", encoding=encoding)\n",
    "    text_file.write(output_string)\n",
    "    text_file.close()\n",
    "\n",
    "\n",
    "def nancy_build_metadata(directory, prompts, SAMPLE_RATE=48000, BIT_DEPTH=2, min_audio_duration=0.8, max_audio_duration=12.0):\n",
    "    Nancy_lookup = {filename: quote[1:-1].strip() for filename, quote in [line[2:-2].split(\" \",1) for line in ((open(prompts, \"r\").read()).splitlines())]}\n",
    "    short_clip_count = long_clip_count = total_clip_count = invalid_clip_count = 0\n",
    "    for audio_file in glob(directory+\"/**/*.wav\", recursive=True):\n",
    "        total_clip_count+=1\n",
    "        if os.stat(audio_file).st_size < int(BIT_DEPTH*SAMPLE_RATE*min_audio_duration): short_clip_count+=1; continue # if file length less than min_audio_duration seconds, skip\n",
    "        if os.stat(audio_file).st_size > int(BIT_DEPTH*SAMPLE_RATE*max_audio_duration): long_clip_count+=1; continue #  if file length greater than max_audio_duration seconds, skip\n",
    "        \n",
    "        audio_filename = \"/\".join(audio_file.split(\"/\")[-1:])\n",
    "        if audio_filename.replace(\".wav\",\"\") in Nancy_lookup.keys():\n",
    "            quote = Nancy_lookup[audio_filename.replace(\".wav\",\"\")]\n",
    "            quote = unidecode(quote)\n",
    "            timestamp = \"00_00_00\"\n",
    "            voice = \"(Audiobook) Blizzard2011_\"+\"Nancy\"\n",
    "            emotions = []\n",
    "            noise_level = \"\"\n",
    "            \n",
    "            if voice.title() in list(metadata.keys()):\n",
    "                metadata[str(voice).title()].append({\"file_path\": audio_file, \"timestamp\": timestamp, \"emotions\": emotions, \"noise_level\": noise_level, \"quote\": quote})\n",
    "            else:\n",
    "                metadata[str(voice).title()] = [{\"file_path\": audio_file, \"timestamp\": timestamp, \"emotions\": emotions, \"noise_level\": noise_level, \"quote\": quote}]\n",
    "        else:\n",
    "            print(f\"{audio_file} Has no Quote.\")\n",
    "    print(str(total_clip_count)+\" Total Clips\")\n",
    "    print(str(short_clip_count)+\" clips are too short\")\n",
    "    print(str(long_clip_count)+\" clips are too long\")\n",
    "    print(str(invalid_clip_count)+\" clips are invalid (bad filename or missing quote)\")\n",
    "    print(str(total_clip_count-(short_clip_count+long_clip_count+invalid_clip_count))+\" clips written into metadata dict\")\n",
    "\n",
    "\n",
    "# metadata[\"celestia\"] =  [{file_path: \"\", timestamp: \"00_00_05\", emotions: [\"neutral\"], noise_level: \"\", quote = \"Once upon a time.\"}, .... , ....]\n",
    "def build_metadata(directory, ignore_dirs=[\"Noise samples\",], SAMPLE_RATE=48000, BIT_DEPTH=2, min_audio_duration=0.8, max_audio_duration=12.0): # uses Global \"directory\" for recursive directory search, for every .wav file it will find the accompanying label and add to metadata.\n",
    "    short_clip_count = 0\n",
    "    long_clip_count = 0\n",
    "    total_clip_count = 0\n",
    "    invalid_clip_count = 0\n",
    "    for dir_ in [x[0] for x in os.walk(directory)]: # recursive directory search\n",
    "        if len(os.listdir(dir_)) < 1: continue\n",
    "        for filename in os.listdir(dir_):\n",
    "            file_path = os.path.join(dir_,filename)\n",
    "            if any([ignoredir in file_path for ignoredir in ignore_dirs]): continue\n",
    "            if filename.endswith(\".wav\"):\n",
    "                total_clip_count+=1\n",
    "                if os.stat(file_path).st_size < int(BIT_DEPTH*SAMPLE_RATE*min_audio_duration): short_clip_count+=1; continue # if file length less than min_audio_duration seconds, skip\n",
    "                if os.stat(file_path).st_size > int(BIT_DEPTH*SAMPLE_RATE*max_audio_duration): long_clip_count+=1; continue #  if file length greater than max_audio_duration seconds, skip\n",
    "                # ---- Unique DATASETs ----\n",
    "                if \"Anons/PostalDude2\" in file_path:\n",
    "                    timestamp = \"00_00_00\"\n",
    "                    voice = \"postal dude\"\n",
    "                    emotions = []\n",
    "                    noise_level = \"\"\n",
    "                    filename_quote = None # missing question marks\n",
    "                elif \"Anons/Rise Kujikawa\" in file_path:\n",
    "                    timestamp = \"00_00_00\"\n",
    "                    voice = \"Rise Kujikawa\"\n",
    "                    emotions = []\n",
    "                    noise_level = \"\"\n",
    "                    filename_quote = None # missing question marks\n",
    "                # ---- Unique DATASETs ----\n",
    "                # ---- VCTK and Clipper Sliced DATASET ----\n",
    "                else:\n",
    "                    splitted = filename.split(\"_\")\n",
    "                    try: # if Clippers MLP dataset\n",
    "                        timestamp = \"_\".join(splitted[0:3])          # 00_00_05\n",
    "                        voice = \"(Show) My Little Pony_\"+splitted[3].title()# celestia\n",
    "                        \n",
    "                        if \"Other/Star Trek (John de Lancie, Discord)\" in file_path:\n",
    "                            voice = \"(Show) Star Trek_\"+\"Q\"\n",
    "                        elif \"Other/Eli, Elite Dangerous (John de Lancie, Discord)\" in file_path:\n",
    "                            voice = \"(Game) Elite Dangerous_\"+\"Eli\"\n",
    "                        elif \"Other/A Little Bit Wicked (Kristin Chenoworth, Skystar)\" in file_path:\n",
    "                            voice = \"(Audiobook) A Little Bit Wicked_\"+splitted[3].title()\n",
    "                        elif \"Other/Sum - Tales From the Afterlives (Emily Blunt, Tempest)\" in file_path:\n",
    "                            voice = \"(Audiobook) Sum - Tales From the Afterlives_\"+splitted[3].title()\n",
    "                        elif \"Other/Dr. Who\" in file_path:\n",
    "                            voice = \"(Audiobook) Dr. Who_\"+splitted[3].title()\n",
    "                        elif \"Other/Dan vs\" in file_path:\n",
    "                            voice = \"(Show) Dan vs_\"+splitted[3].title()\n",
    "                        elif \"Other/TFH\" in file_path:\n",
    "                            voice = \"(Game) Them's Fightin' Herds_\"+splitted[3].title()\n",
    "                        elif \"/FoE s1e01 Radioplay\" in file_path:\n",
    "                            voice = \"(Audiodrama) Fallout Equestria_\"+splitted[3].title()\n",
    "                        elif \"/FoE s1e02 Radio Play\" in file_path:\n",
    "                            voice = \"(Audiodrama) Fallout Equestria_\"+splitted[3].title()\n",
    "                        elif \"/Songs\" in file_path:\n",
    "                            voice = \"(Music) My Little Pony_\"+splitted[3].title()\n",
    "                        elif \"Anons/Blaze\" in file_path:\n",
    "                            voice = \"(Game) Sonic_\"+splitted[3].title()\n",
    "                        \n",
    "                        emotions = splitted[4].lower().split(\" \")   # neutral\n",
    "                        noise_level = splitted[5].lower()           # \"\" = clean, \"noisy\" = Noisy, \"very noisy\" = Very Noisy\n",
    "                        filename_quote = unidecode(splitted[6]) # missing question marks\n",
    "                    except:\n",
    "                        if (os.path.basename(dir_).startswith(\"p\")): # if VCTK then use this\n",
    "                            emotions = []; noise_level = \"\"; timestamp = \"00_00_00\"; voice = \"VCTK (News Extracts)_\"+os.path.basename(dir_)\n",
    "                        else:\n",
    "                            print(\"'\"+file_path+\"' is not a valid filename\")\n",
    "                            invalid_clip_count+=1; continue\n",
    "                # ---- VCTK and Clipper Sliced DATASET ----\n",
    "                try:\n",
    "                    try:\n",
    "                        with open(os.path.join(dir_,filename.replace(\".wav\",\".txt\")), 'r', encoding=\"utf-8\") as file:\n",
    "                            txt_quote = unidecode(file.read().replace('\\n', '')) # Once upon a time.\n",
    "                    except:\n",
    "                        with open(os.path.join(dir_,filename.replace(\".wav\",\".txt\")), 'r', encoding=\"latin-1\") as file:\n",
    "                            txt_quote = unidecode(file.read().replace('\\n', '')) # Once upon a time.\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    invalid_clip_count+=1; continue\n",
    "                if voice.title() in list(metadata.keys()):\n",
    "                    metadata[str(voice).title()].append({\"file_path\": file_path, \"timestamp\": timestamp, \"emotions\": emotions, \"noise_level\": noise_level, \"quote\": txt_quote})\n",
    "                else:\n",
    "                    metadata[str(voice).title()] = [{\"file_path\": file_path, \"timestamp\": timestamp, \"emotions\": emotions, \"noise_level\": noise_level, \"quote\": txt_quote}]\n",
    "            else:\n",
    "                continue\n",
    "    print(str(total_clip_count)+\" Total Clips\")\n",
    "    print(str(short_clip_count)+\" clips are too short\")\n",
    "    print(str(long_clip_count)+\" clips are too long\")\n",
    "    print(str(invalid_clip_count)+\" clips are invalid (bad filename or missing TXT)\")\n",
    "    print(str(total_clip_count-(short_clip_count+long_clip_count+invalid_clip_count))+\" clips written into metadata dict\")\n",
    "\n",
    "\n",
    "def write_datasets(speaker_id = 0, permitted_noise_levels = [\"\"], minimum_clips=3, start_token=\"\", end_token=\"\", percentage_training_data=0.96): \n",
    "    print(\"Filtering Metadata for desired files\")\n",
    "    multi_speaker_lines = []\n",
    "    speaker_ids = []\n",
    "    speaker_ids_done = []\n",
    "    for voice in list(metadata.keys()):\n",
    "        meta = metadata[voice] # meta == [{file_path: \"\", timestamp: \"00_00_05\", emotions: [\"neutral\"], noise_level: \"\", quote = \"Once upon a time.\"}, .... , ....]\n",
    "        if len(meta) < minimum_clips: continue # ignore voices with less than 3 clips of audio\n",
    "        single_speaker_lines = []\n",
    "        for clip in meta:\n",
    "            if (clip[\"noise_level\"] in permitted_noise_levels):\n",
    "                single_speaker_lines.append(clip[\"file_path\"]+\"|\"+start_token+clip[\"quote\"]+end_token)\n",
    "                multi_speaker_lines.append (clip[\"file_path\"]+\"|\"+start_token+clip[\"quote\"]+end_token+\"|\"+str(speaker_id))\n",
    "                if speaker_id not in speaker_ids_done: speaker_ids_done.append(speaker_id); speaker_ids.append(f\"|{voice}|{speaker_id}\")\n",
    "        speaker_id+=1 # next speaker_id for next voice\n",
    "    # shuffle stuff\n",
    "    shuffled_multi_speaker_lines = multi_speaker_lines\n",
    "    shuffle(shuffled_multi_speaker_lines)\n",
    "    num_clips = len(shuffled_multi_speaker_lines)\n",
    "    train_end = int(num_clips * percentage_training_data)\n",
    "    train_arr = shuffled_multi_speaker_lines[:train_end]; validation_arr = shuffled_multi_speaker_lines[train_end:]\n",
    "    \n",
    "    # also make unshuffled stuff (sorted by speaker_id)\n",
    "    unshuffled_multi_speaker_lines = []\n",
    "    for i in range(len(list(metadata.keys()))):\n",
    "        for line in multi_speaker_lines:\n",
    "            if line.split(\"|\")[2] == str(i): unshuffled_multi_speaker_lines.append(line)\n",
    "    # Write all this crap to files\n",
    "    write_files(unshuffled_multi_speaker_lines, speaker_ids, train_arr, validation_arr, output_directory_=DIRECTORY_GLOBAL)\n",
    "\n",
    "\n",
    "def write_files(multi_speaker_lines, speaker_ids, train_arr, val_arr, output_directory_):\n",
    "    output_directory = os.path.join(output_directory_,\"filelists\")\n",
    "    print(f\"Writing Metadata files to {output_directory}.\\nPlease Wait.\")\n",
    "    if not os.path.exists(output_directory): os.makedirs(output_directory)\n",
    "    \n",
    "    # generate files of speaker ID's\n",
    "    text_file = open(os.path.join(output_directory,\"speaker_ids.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(speaker_ids)); text_file.close()\n",
    "    \n",
    "    # generate mel text dataset metadata\n",
    "    text_file = open(os.path.join(output_directory,\"mel_train_taca2.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(train_arr).replace(\".wav|\",\".npy|\")); text_file.close()\n",
    "    arpabet(os.path.join(output_directory,\"mel_train_taca2.txt\"),os.path.join(output_directory,\"mel_train_taca2_arpa.txt\"))\n",
    "    # generate mel arpabet dataset metadata\n",
    "    text_file = open(os.path.join(output_directory,\"mel_validation_taca2.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(val_arr).replace(\".wav|\",\".npy|\")); text_file.close()\n",
    "    arpabet(os.path.join(output_directory,\"mel_validation_taca2.txt\"),os.path.join(output_directory,\"mel_validation_taca2_arpa.txt\"))\n",
    "    # generate mel merged dataset metadata\n",
    "    concat_text([os.path.join(output_directory,\"mel_train_taca2.txt\"), os.path.join(output_directory,\"mel_train_taca2_arpa.txt\")], os.path.join(output_directory,\"mel_train_taca2_merged.txt\"))\n",
    "    concat_text([os.path.join(output_directory,\"mel_validation_taca2.txt\"), os.path.join(output_directory,\"mel_validation_taca2_arpa.txt\")], os.path.join(output_directory,\"mel_validation_taca2_merged.txt\"))\n",
    "    print(\"mel filepaths ready\")\n",
    "    \n",
    "    # generate text dataset metadata\n",
    "    text_file = open(os.path.join(output_directory,\"unshuffled_taca2.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(multi_speaker_lines)); text_file.close()\n",
    "    \n",
    "    # generate text dataset metadata\n",
    "    text_file = open(os.path.join(output_directory,\"train_taca2.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(train_arr)); text_file.close()\n",
    "    arpabet(os.path.join(output_directory,\"train_taca2.txt\"),os.path.join(output_directory,\"train_taca2_arpa.txt\"))\n",
    "    # generate arpabet dataset metadata\n",
    "    text_file = open(os.path.join(output_directory,\"validation_taca2.txt\"), \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(\"\\n\".join(val_arr)); text_file.close()\n",
    "    arpabet(os.path.join(output_directory,\"validation_taca2.txt\"),os.path.join(output_directory,\"validation_taca2_arpa.txt\"))\n",
    "    # generate merged dataset metadata\n",
    "    concat_text([os.path.join(output_directory,\"train_taca2.txt\"), os.path.join(output_directory,\"train_taca2_arpa.txt\")], os.path.join(output_directory,\"train_taca2_merged.txt\"))\n",
    "    concat_text([os.path.join(output_directory,\"validation_taca2.txt\"), os.path.join(output_directory,\"validation_taca2_arpa.txt\")], os.path.join(output_directory,\"validation_taca2_merged.txt\"))\n",
    "    \n",
    "    print(\"Finished!\")\n",
    "\n",
    "\n",
    "def convert_dir_to_wav(directory, SAMPLE_RATE=48000, BIT_DEPTH=2, ignore_dirs=[\"Noise samples\"], continue_from=0, skip_existing=False):\n",
    "    skip = 0\n",
    "    tqdm.write(\"Converting flacs to wavs\")\n",
    "    for index, file_path in tqdm(enumerate(glob(directory+\"/**/*.flac\", recursive=True)), total=len(glob(directory+\"/**/*.flac\", recursive=True)), smoothing=0): # recursive directory search\n",
    "        if index < continue_from: continue\n",
    "        if skip_existing and os.path.exists(file_path.replace(\".flac\",\".wav\")): continue\n",
    "        for filter_dir in ignore_dirs:\n",
    "            if filter_dir in file_path: tqdm.write(\"Skipping \"+file_path); skip = 1; break\n",
    "        if skip: skip = 0; continue\n",
    "        if file_path.endswith(\"_mic1.flac\"):\n",
    "            os.rename(file_path,file_path.replace(\"_mic1.flac\",\".flac\"))\n",
    "        if file_path.endswith(\"_mic2.flac\"): tqdm.write(\"Skipping \"+file_path); continue\n",
    "        if file_path.endswith(\".flac\"):\n",
    "            #tqdm.write(file_path+\" --> \"+file_path.replace(\".flac\",\".wav\"))\n",
    "            os.system('flac --decode \"'+(file_path.replace(\"_mic1.flac\",\".flac\"))+'\" -f -s')\n",
    "            #converter.flac2wav(file_path, file_path.replace(\".flac\",\".wav\"), \"flac\", frame_rate=SAMPLE_RATE, sample_width=BIT_DEPTH) # sample_width is bit_depth in bytes eg: 2 = 16 bit audio.\n",
    "\n",
    "\n",
    "def convert_dir_to_wav_multiprocess(file_paths_arr, SAMPLE_RATE=48000, BIT_DEPTH=2, ignore_dirs=[\"Noise samples\"], continue_from=0, skip_existing=False):\n",
    "    skip = 0\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.01): # recursive directory search\n",
    "        if skip_existing and os.path.exists(file_path.replace(\".flac\",\".wav\")): continue\n",
    "        for filter_dir in ignore_dirs:\n",
    "            if filter_dir in file_path: tqdm.write(\"Skipping \"+file_path); skip = 1; break\n",
    "        if skip: skip = 0; continue\n",
    "        if file_path.endswith(\"_mic1.flac\"):\n",
    "            os.rename(file_path,file_path.replace(\"_mic1.flac\",\".flac\"))\n",
    "        if file_path.endswith(\"_mic2.flac\"): tqdm.write(\"Skipping \"+file_path); continue\n",
    "        if file_path.endswith(\".flac\"):\n",
    "            #song = AudioSegment.from_flac(file_path)\n",
    "            #print(\"banan\")\n",
    "            #song.export(file_path.replace(\".flac\",\".wav\"), format = \"wav\", bitrate=str(SAMPLE_RATE))\n",
    "            os.system('flac --decode \"'+(file_path.replace(\"_mic1.flac\",\".flac\"))+'\" -f -s')\n",
    "\n",
    "\n",
    "def set_wavs_to_mono(directory):\n",
    "    tqdm.write(\"Setting wavs to mono\")\n",
    "    for file_path in tqdm(glob(directory+\"/**/*.wav\", recursive=True), smoothing=0): # recursive directory search\n",
    "        #tqdm.write(file_path)\n",
    "        sound = AudioSegment.from_wav(file_path)\n",
    "        if sound.channels > 1:\n",
    "            sound = sound.set_channels(1)\n",
    "            sound.export(file_path, format=\"wav\")\n",
    "\n",
    "\n",
    "def set_wavs_to_mono_multiprocess(file_paths_arr):\n",
    "    for file_path in file_paths_arr: # recursive directory search\n",
    "        sound = AudioSegment.from_wav(file_path)\n",
    "        if sound.channels > 1:\n",
    "            tqdm.write(file_path)\n",
    "            sound = sound.set_channels(1)\n",
    "            sound.export(file_path, format=\"wav\")\n",
    "\n",
    "\n",
    "def normalize_wav_volumes_mixmode(directory, amplitude=0.08):\n",
    "    subdirectories = [x[0] for x in os.walk(directory)]\n",
    "    for subdirectory in subdirectories:\n",
    "        os.system(f\"normalize-audio -a {amplitude} -b '{subdirectory}/'*.wav\")\n",
    "\n",
    "def pad_wavs():\n",
    "    tqdm.write(\"Padding Wavs\")\n",
    "    os.system(\"powershell '/media/cookie/Samsung PM961/Pad_Dataset.ps1'\")\n",
    "    tqdm.write(\"Replacing wavs with Padded wavs\")\n",
    "    force_move_dir(\"/media/cookie/Samsung 860 QVO/ClipperDatasetV2_Padded\",\"/media/cookie/Samsung 860 QVO/ClipperDatasetV2\")\n",
    "\n",
    "\n",
    "def fix_wavs(directory, SAMPLE_RATE=48000, BIT_DEPTH=2):\n",
    "    tqdm.write(\"Setting Wavs to 48Khz 16 bit Mono\")\n",
    "    #os.system(\"powershell '/media/cookie/Samsung PM961/Fix_Dataset.ps1'\")\n",
    "    reset_directory_structure(directory, directory.replace(\"/ClipperDatasetV2\",\"/ClipperDatasetV2_Fixed\"))\n",
    "    for file_path in tqdm(glob(directory+\"/**/*.wav\", recursive=True), smoothing=0): # recursive directory search\n",
    "        file_pathB = file_path.replace(\"/ClipperDatasetV2\",\"/ClipperDatasetV2_Fixed\")\n",
    "        os.system('sox \"'+file_path+'\" -r '+str(SAMPLE_RATE)+' -c 1 -b '+str(BIT_DEPTH*8)+' \"'+file_pathB+'\"')\n",
    "    tqdm.write(\"Replacing wavs with 48Khz 16 bit Mono wavs\")\n",
    "    force_move_dir(\"/media/cookie/Samsung 860 QVO/ClipperDatasetV2_Fixed\",\"/media/cookie/Samsung 860 QVO/ClipperDatasetV2\")\n",
    "\n",
    "\n",
    "def clean_VCTK(directory, noiseprof_path, denoise_strength=0.40):\n",
    "    tqdm.write(\"Cleaning VCTK Wavs\")\n",
    "#    os.system(\"powershell '/media/cookie/Samsung PM961/RemoveNoise_Dataset.ps1'\") # old Powershell method\n",
    "    reset_directory_structure(directory, directory.replace(\"/wav\",\"/wavCleaned\"))\n",
    "    for file_path in tqdm(glob(directory+\"/**/*.wav\", recursive=True), smoothing=0): # recursive directory search\n",
    "        os.system('sox \"'+file_path+'\" \"'+(file_path.replace(\"/wav\",\"/wavCleaned\"))+'\" noisered \"'+noiseprof_path+f'\" {denoise_strength}')\n",
    "    tqdm.write(\"Replacing wavs with Cleaned wavs\")\n",
    "\n",
    "\n",
    "def clean_VCTK_multiprocess(file_paths_arr, noiseprof_path, denoise_strength=0.40):\n",
    "    tqdm.write(\"Cleaning VCTK Wavs\")\n",
    "#    os.system(\"powershell '/media/cookie/Samsung PM961/RemoveNoise_Dataset.ps1'\") # old Powershell method\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.0): # recursive directory search\n",
    "        os.system('sox \"'+file_path+'\" \"'+(file_path.replace(\"/wav\",\"/wavCleaned\"))+'\" noisered \"'+noiseprof_path+f'\" {denoise_strength}')\n",
    "    tqdm.write(\"Replacing wavs with Cleaned wavs\")\n",
    "\n",
    "\n",
    "def AIO_wavs(directory, PADDING_BEFORE_CLIP=0.025, PADDING_AFTER_CLIP=0.025, SAMPLE_RATE=48000, BIT_DEPTH=2):\n",
    "    tqdm.write(\"Normalizing, Padding and Fixing Dataset\")\n",
    "    #os.system(\"powershell '/media/cookie/Samsung PM961/All_in_one_Dataset.ps1'\")\n",
    "\n",
    "    for file_path in tqdm(glob(directory+\"/**/*.wav\", recursive=True), smoothing=0): # recursive directory search\n",
    "        file_pathB = file_path.replace(\"/ClipperDatasetV2\",\"/ClipperDatasetV2_Padded\")\n",
    "        #os.system('normalize-audio \"'+file_path+'\" -a 0.03125; sox \"'+file_path+'\" -r '+str(SAMPLE_RATE)+' -c 1 -b '+str(BIT_DEPTH*8)+' \"'+file_pathB+'\"; sox \"'+file_pathB+'\" \"'+file_path+'\" pad '+str(PADDING_BEFORE_CLIP)+' '+str(PADDING_BEFORE_CLIP))\n",
    "        os.system('sox \"'+file_path+'\" -r '+str(SAMPLE_RATE)+' -c 1 -b '+str(BIT_DEPTH*8)+' \"'+file_pathB+'\"; sox \"'+file_pathB+'\" \"'+file_path+'\" pad '+str(PADDING_BEFORE_CLIP)+' '+str(PADDING_BEFORE_CLIP))\n",
    "\n",
    "\n",
    "def AIO_wavs_multiprocess(file_paths_arr, PADDING_BEFORE_CLIP=0.0, PADDING_AFTER_CLIP=0.0125, SAMPLE_RATE=48000, BIT_DEPTH=2):\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.0): # recursive directory search\n",
    "        file_pathB = file_path.replace(\"/ClipperDatasetV2\",\"/ClipperDatasetV2_Padded\")\n",
    "        #os.system('normalize-audio \"'+file_path+'\" -a 0.03125; sox \"'+file_path+'\" -r '+str(SAMPLE_RATE)+' -c 1 -b '+str(BIT_DEPTH*8)+' \"'+file_pathB+'\"; sox \"'+file_pathB+'\" \"'+file_path+'\" pad '+str(PADDING_BEFORE_CLIP)+' '+str(PADDING_BEFORE_CLIP))\n",
    "        os.system('sox \"'+file_path+'\" -r '+str(SAMPLE_RATE)+' -c 1 -b '+str(BIT_DEPTH*8)+' \"'+file_pathB+'\"; sox \"'+file_pathB+'\" \"'+file_path+'\" pad '+str(PADDING_BEFORE_CLIP)+' '+str(PADDING_BEFORE_CLIP))\n",
    "\n",
    "\n",
    "def trim_wavs(directory, SAMPLE_RATE=48000, top_db=30, window_length=8192, hop_length=128, ref=np.max):\n",
    "    tqdm.write(\"Trimming Wavs\")\n",
    "    for file_path in tqdm(glob(directory+\"/**/*.wav\", recursive=True), smoothing=0): # recursive directory search\n",
    "        try:\n",
    "            sound, _ = librosa.core.load(file_path, sr=SAMPLE_RATE)\n",
    "            trimmed_sound, index = librosa.effects.trim(sound, top_db=top_db, frame_length=window_length, hop_length=hop_length, ref=ref) # gonna be a little messed up for different sampling rates\n",
    "        except Exception as ex:\n",
    "            tqdm.write(\"\\n\\n\"+file_path+\" is corrupt\"+str(ex)); os.system('rm \"'+file_path+'\"')\n",
    "        librosa.output.write_wav(file_path, trimmed_sound, SAMPLE_RATE)\n",
    "\n",
    "\n",
    "def trim_wavs_multiprocess(file_paths_arr, SAMPLE_RATE=48000, margin_left=0, margin_right=0, top_db=30, window_length=8192, hop_length=128, ref=np.max, preemphasis_strength=0.50):\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.0): # recursive directory search\n",
    "        try:\n",
    "            sound, _ = librosa.core.load(file_path, sr=SAMPLE_RATE)\n",
    "            sound_filt = librosa.effects.preemphasis(sound, coef=preemphasis_strength)\n",
    "            trimmed_sound, index = librosa.effects.trim(sound_filt, top_db=top_db, frame_length=window_length, hop_length=hop_length, ref=ref) # gonna be a little messed up for different sampling rates\n",
    "            trimmed_sound = sound[max(index[0]-margin_left,0):index[1]+margin_right]\n",
    "            print(index)\n",
    "            if len(sound) != len(trimmed_sound):\n",
    "                librosa.output.write_wav(file_path, trimmed_sound, SAMPLE_RATE)\n",
    "            else:\n",
    "                print(file_path, \"does not need trimming\")\n",
    "        except Exception as ex:\n",
    "            tqdm.write(\"\\n\\n\"+file_path+\" is corrupt\"+str(ex)); os.system('rm \"'+file_path+'\"')\n",
    "\n",
    "\n",
    "def high_pass_filter_wavs_multiprocess(file_paths_arr, cutoff_freq, strength):\n",
    "    import soundfile as sf\n",
    "    import scipy\n",
    "    from scipy import signal\n",
    "    \n",
    "    prev_sr = 0\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.0): # recursive directory search\n",
    "            audio, sample_rate = sf.read(file_path) # load audio to RAM\n",
    "            if sample_rate != prev_sr:\n",
    "                sos = signal.butter(strength, cutoff_freq, 'hp', fs=sample_rate, output='sos') # calcuate filter somethings\n",
    "                prev_sr = sample_rate\n",
    "            filtered_audio = signal.sosfilt(sos, audio) # apply filter\n",
    "            sf.write(file_path, filtered_audio, sample_rate) # write back to disk\n",
    "\n",
    "\n",
    "def reset_padding(directory, SAMPLE_RATE=48000):\n",
    "    trim_wavs(directory, SAMPLE_RATE=SAMPLE_RATE, top_db=60, window_length=256)\n",
    "\n",
    "\n",
    "def multithread_directory_wavs(function, directory, threads=16):\n",
    "    from random import shuffle\n",
    "    p = Pool(threads)\n",
    "    file_paths = glob(directory+\"/**/*.wav\", recursive=True)\n",
    "    shuffle(file_paths)\n",
    "    split_file_paths = list(even_split(file_paths,threads))\n",
    "    print(p.map(function, split_file_paths))\n",
    "\n",
    "\n",
    "def multiprocess_directory_wavs(function, directory, threads=16):\n",
    "    from random import shuffle\n",
    "    p = Pool(threads)\n",
    "    file_paths = glob(directory+\"/**/*.wav\", recursive=True)\n",
    "    shuffle(file_paths)\n",
    "    split_file_paths = list(even_split(file_paths,threads))\n",
    "    #with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #    print(executor.map(function, split_file_paths))\n",
    "    print(p.map(function, split_file_paths))\n",
    "\n",
    "\n",
    "def multiprocess_directory_flacs(function, directory, threads=16):\n",
    "    from random import shuffle\n",
    "    p = Pool(threads)\n",
    "    file_paths = glob(directory+\"/**/*.flac\", recursive=True)\n",
    "    shuffle(file_paths)\n",
    "    split_file_paths = list(even_split(file_paths,threads))\n",
    "    #with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #    print(executor.map(function, split_file_paths))\n",
    "    print(p.map(function, split_file_paths))\n",
    "\n",
    "\n",
    "def multiprocess_filearray(function, file_paths, threads=16):\n",
    "    p = Pool(threads)\n",
    "    split_file_paths = list(even_split(file_paths,threads))\n",
    "    #with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #    print(executor.map(function, split_file_paths))\n",
    "    print(p.map(function, split_file_paths))\n",
    "\n",
    "\n",
    "def convertWavsToFlac(array, SAMPLE_RATE=48000):\n",
    "    from pydub import AudioSegment\n",
    "    for path in array:\n",
    "        if path.endswith('.wav'):\n",
    "            song = AudioSegment.from_wav(path)\n",
    "            song.export(path.replace(\".wav\",\".flac\"),format = \"flac\", bitrate=str(SAMPLE_RATE))\n",
    "\n",
    "\n",
    "def NancySplitRawIntoClips(directory, label_folder, Nancy_CorpusToArchive, SAMPLE_RATE=96000):\n",
    "    \"\"\"\n",
    "    Take original 96Khz studio files and match them with the filenames used for the quote files.\n",
    "    \"\"\"\n",
    "    Nancy_ignore = {studio: output for output, studio, exception in [line.split(\"\\t\") for line in ((open(Nancy_CorpusToArchive, \"r\").read()).splitlines())] if exception}\n",
    "    print(Nancy_ignore)\n",
    "    Nancy_lookup = {studio: output for output, studio, exception in [line.split(\"\\t\") for line in ((open(Nancy_CorpusToArchive, \"r\").read()).splitlines())]}\n",
    "    \n",
    "    os.makedirs(os.path.join(directory,'Sliced'), exist_ok=True)\n",
    "    available_labels = [\"/\".join(x.split(\"/\")[-1:]) for x in glob(label_folder+\"/*.txt\")]\n",
    "    available_audio = glob(directory+\"/*.wav\")\n",
    "    for audio_file in available_audio:\n",
    "        print(audio_file)\n",
    "        audio_filename = \"/\".join(audio_file.split(\"/\")[-1:])\n",
    "        audio_basename = audio_filename.replace(\".wav\",\"\")\n",
    "        audio_basename = audio_basename.replace(\"341_763\",\"343_763\") # exception, easier than rewriting entire label file\n",
    "        ID_offset = int(audio_basename.split(\"_\")[-2]) - 1\n",
    "        ID_end = int(audio_basename.split(\"_\")[-1]) - 1\n",
    "        Prepend_ID = \"_\".join(audio_basename.split(\"_\")[:-2]) # empty unless ARCTIC or LTI files\n",
    "        if Prepend_ID: Prepend_ID += \"_\"\n",
    "        if audio_filename.replace(\".wav\",\".txt\") in available_labels:\n",
    "            label_path = os.path.join(label_folder, audio_filename.replace(\".wav\",\".txt\") ) # get label file\n",
    "            beeps = []\n",
    "            for line in ((open(label_path, \"r\").read()).splitlines()):\n",
    "                beeps+=[line.split(\"\\t\")] # [beep_start, beep_stop, ID]\n",
    "            print(\"beep count\", len(beeps))\n",
    "            print(\"ID_offset\", ID_offset)\n",
    "            print(\"ID_end\", ID_end)\n",
    "            print(\"end - offset\", ID_end-ID_offset)\n",
    "            assert (len(beeps)-1) == (ID_end-ID_offset), \"Ensure each beep is labelled and matches the ArchiveMap\"\n",
    "            sound, _ = librosa.core.load(audio_file, sr=SAMPLE_RATE)\n",
    "            for i in range(len(beeps)):\n",
    "                clip_start = int(float(beeps[i][1])*SAMPLE_RATE) # end of previous beep\n",
    "                clip_end = int(float(beeps[i+1][0])*SAMPLE_RATE) if i+1 < len(beeps) else len(sound) # start of next beep or end of file if no beeps left\n",
    "                ID = Prepend_ID + str(ID_offset + int(beeps[i][2]))\n",
    "                if ID in Nancy_ignore.keys(): continue\n",
    "                print(ID,\"-->\",Nancy_lookup[ID])\n",
    "                ID = Nancy_lookup[ID]\n",
    "                clip_outpath = os.path.join(directory, 'Sliced', ID+\".wav\")\n",
    "                sound_clipped = sound[clip_start:clip_end]\n",
    "                librosa.output.write_wav(clip_outpath, sound_clipped, SAMPLE_RATE)\n",
    "        else:\n",
    "            print(audio_file, \"doesn't have an available label\")\n",
    "\n",
    "\n",
    "def uniqueElems(mylist):\n",
    "    used = set()\n",
    "    return [x for x in mylist if x not in used and (used.add(x) or True)]\n",
    "\n",
    "\n",
    "def ClipperSplitRawIntoClips(working_dir, source_dir, label_dir, verbose=False, explicit_merge=False, MAX_FILENAME_LENGTH=120):\n",
    "    \"\"\"\n",
    "    Take original MLP Episode files and split them into individual clips.\n",
    "    Also merge neighbouring clips to create longer clips and merge clips of ponies speaking to each-other.\n",
    "    \n",
    "    S1-S8 Episode Audio: https://files.catbox.moe/2q4p2z.torrent\n",
    "    Clippers MEGA Folder: https://mega.nz/#F!L952DI4Q!nibaVrvxbwgCgXMlPHVnVw!fwYlhK7B\n",
    "    \n",
    "    INPUTS:\n",
    "        working_dir - will contain the outputs and any temp files\n",
    "        source_dir - should contain original unclipped episode files downloaded from https://files.catbox.moe/2q4p2z.torrent\n",
    "        label_dir - should contain episode labels from clippers MEGA folder\n",
    "    RETURNS:\n",
    "        null\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.join(working_dir,'Sliced'), exist_ok=True)\n",
    "    label_paths = glob(label_dir+\"/*.txt\")\n",
    "    unclipped_paths = glob(source_dir+\"/**/*.wav\", recursive=True)\n",
    "    \n",
    "    # ---------- LINK THE LABELS TO FILES ----------\n",
    "    linked_paths = [] # dictionary of labels -> unclipped wavs\n",
    "    for label_path_ in label_paths:\n",
    "        label_path = label_path_ # get a temp varable to fuck about with\n",
    "        if any(True for x in [\"_izo.txt\",\"_original.txt\",\"_unmix.txt\"] if x in label_path): continue # ignore any izo, orignal or unmix labels.\n",
    "        if \"fim_s01\" in label_path:\n",
    "            episode = label_path.split(\"fim_s01\")[1][:3]\n",
    "            #print(episode)\n",
    "            matching_audio = [x for x in unclipped_paths if (\"mlp.s01\"+episode in x)] # get all audio files that potentially match this label file.\n",
    "            if len(matching_audio) > 1: print(\"Too many potential matches:\\nmaching_audio = \", matching_audio); raise Exception(\"Multiple episodes match a label file.\")\n",
    "            if not len(matching_audio): print(\"label_path_ = \", label_path_); raise Exception(\"Label has no matching audio file.\")\n",
    "            \n",
    "            linked_paths.append({label_path_: matching_audio[0]})\n",
    "            unclipped_paths.remove(matching_audio[0])\n",
    "            continue\n",
    "        elif \"_outtakes.txt\" in label_path:\n",
    "            continue # for later\n",
    "        elif \"_special source.txt\" in label_path:\n",
    "            continue # for later\n",
    "        elif \"fim_s09\" in label_path:\n",
    "            continue # for later\n",
    "        elif \"fim_s\" in label_path: # all seasons other than s01\n",
    "            episode = label_path.split(\"fim_s\")[1][2:5]\n",
    "            season = \"S\"+label_path.split(\"fim_s\")[1][:2]\n",
    "            s_ep = (season + episode).upper()\n",
    "            \n",
    "            matching_audio = [x for x in unclipped_paths if (s_ep in x)] # get all audio files that potentially match this label file.\n",
    "            if len(matching_audio) > 1: print(\"Too many potential matches:\\nmaching_audio = \", matching_audio); raise Exception(\"Multiple episodes match a label file.\")\n",
    "            if not len(matching_audio): print(\"label_path_ = \", label_path_); raise Exception(\"Label has no matching audio file.\")\n",
    "            linked_paths.append({label_path_: matching_audio[0]})\n",
    "            unclipped_paths.remove(matching_audio[0])\n",
    "            continue\n",
    "    \n",
    "    if verbose:\n",
    "        for l in linked_paths:\n",
    "            print(l, \"\")\n",
    "    \n",
    "    for i, linked_path in enumerate(linked_paths):\n",
    "        label_path, audio_path = list(linked_path.items())[0]\n",
    "        base_audio_dirs = []\n",
    "        labels = []\n",
    "        for line in ((open(label_path, \"r\").read()).splitlines()):\n",
    "            labels+=[line.split(\"\\t\")] # [label_start, label_stop, time_voice_emotion_noise_quote]\n",
    "        \n",
    "        audio, _ = librosa.core.load(audio_path, sr=SAMPLE_RATE)\n",
    "        \n",
    "        # relative dir to store audio data\n",
    "        if \"fim_s\" in label_path: # all seasons other than s01\n",
    "            episode = label_path.split(\"fim_s\")[1][2:5]\n",
    "            season = \"S\"+label_path.split(\"fim_s\")[1][:2]\n",
    "            s_ep = (season + episode).upper()\n",
    "            base_audio_dirs.append(season)\n",
    "            base_audio_dirs.append(episode)\n",
    "        \n",
    "        prev_label = [-10, -10, \"00_00_00_Null_Null_Noisy_\"]\n",
    "        for label in tqdm(labels, leave=False, desc=f\"{i}/{len(linked_paths)}\"):\n",
    "            audio_dirs = base_audio_dirs # get relative output path back to [\"S01\",\"E01\"]\n",
    "            label_start, label_stop, info = label\n",
    "            *time_stamp, voice, str_emotion, noise_level, quote = info.split(\"_\") # 00_00_05_Celestia_Neutral__Once upon a time. -> [[\"00\",\"00\",\"05\"],\"Celestia\",\"Neutral\",\"\",\"Once upon a time.\"]\n",
    "            emotions = str_emotion.split(\" \") # \"Happy Shouting\" -> [\"Happy\",\"Shouting\"]\n",
    "            \n",
    "            prev_label_start, prev_label_stop, prev_info = prev_label\n",
    "            *prev_time_stamp, prev_voice, prev_str_emotion, prev_noise_level, prev_quote = prev_info.split(\"_\") # 00_00_05_Celestia_Neutral__Once upon a time. -> [[\"00\",\"00\",\"05\"],\"Celestia\",\"Neutral\",\"\",\"Once upon a time.\"]\n",
    "            prev_emotions = prev_str_emotion.split(\" \") # \"Happy Shouting\" -> [\"Happy\",\"Shouting\"]\n",
    "            \n",
    "            time_between_clips = float(label_start) - float(prev_label_stop) # time between start of this clip and end of the last clip\n",
    "            prev_label_start_sample = int(float(prev_label_start)*SAMPLE_RATE)\n",
    "            prev_label_stop_sample = int(float(prev_label_stop)*SAMPLE_RATE)\n",
    "            label_start_sample = int(float(label_start)*SAMPLE_RATE)\n",
    "            label_stop_sample = int(float(label_stop)*SAMPLE_RATE)\n",
    "            \n",
    "            # get more accurate silent time between clips\n",
    "            if (float(prev_label_stop)-float(prev_label_start)) > 0.025: # if time_between clips longer than 25ms and previous clip has duration longer than 25ms\n",
    "                def return_ref(input):\n",
    "                    return 0.0000250# 0.0000020 for trimming silence but leaving breathing in. # 0.0000250 for trimming silence and also quiet breathing.\n",
    "                clipped_audio = audio[prev_label_start_sample:prev_label_stop_sample] # previous sample\n",
    "                index = librosa.effects.trim(clipped_audio, top_db=0, frame_length=int(SAMPLE_RATE*0.100), hop_length=int(SAMPLE_RATE*0.0125), ref=return_ref)[1] # gonna be a little messed up for different sampling rates\n",
    "                prev_label_stop_speech_sample = prev_label_start_sample+index[1] # when previous loud speech stop, ignores breating and is a rough trim\n",
    "                #prev_label_start_sample = prev_label_start_sample+index[0]\n",
    "                clipped_audio = audio[label_start_sample:label_stop_sample] # current sample\n",
    "                index = librosa.effects.trim(clipped_audio, top_db=0, frame_length=int(SAMPLE_RATE*0.100), hop_length=int(SAMPLE_RATE*0.0125), ref=return_ref)[1] # gonna be a little messed up for different sampling rates\n",
    "                #label_stop_sample = label_start_sample+index[1]\n",
    "                label_start_speech_sample = label_start_sample+index[0] # when loud speech starts, ignores breating and is a rough trim\n",
    "                time_between_clips = (label_start_speech_sample - prev_label_stop_speech_sample)/SAMPLE_RATE # time where there is only silence or very quiet breathing.\n",
    "                \n",
    "                # this block does the same as above, just in one dense line and gets the silent time rather than quiet time between clips.\n",
    "                def return_ref(input):\n",
    "                    return 0.0000020# 0.0000020 for trimming silence but leaving breathing in. # 0.0000250 for trimming silence and also quiet breathing.\n",
    "                silent_time_between_clips = ((label_start_sample+librosa.effects.trim(audio[label_start_sample:label_stop_sample], top_db=0, frame_length=int(SAMPLE_RATE*0.100), hop_length=int(SAMPLE_RATE*0.0125), ref=return_ref)[1][0]) - (prev_label_start_sample+librosa.effects.trim(audio[prev_label_start_sample:prev_label_stop_sample], top_db=0, frame_length=int(SAMPLE_RATE*0.100), hop_length=int(SAMPLE_RATE*0.0125), ref=return_ref)[1][1]))/SAMPLE_RATE # time where there is only silence or very quiet breathing. \n",
    "                \n",
    "                # get rough volume between clips\n",
    "                audio_between_clips = audio[prev_label_stop_speech_sample:label_start_speech_sample]\n",
    "                std_between_clips = np.std(audio_between_clips) if len(audio_between_clips) > 10 else 0\n",
    "            \n",
    "            # --- DO STUFF ---\n",
    "            \n",
    "            if time_between_clips < 0.8 and noise_level == \"\" and prev_noise_level == \"\":\n",
    "                clipped_audio = audio[prev_label_start_sample:label_stop_sample]\n",
    "                assert len(clipped_audio), f\"LABEL: {label}\\nFILE: {label_path}\\ndid not process correctly. Output audio has 0 length.\"\n",
    "                \n",
    "                if prev_voice.lower() == voice.lower():\n",
    "                    audio_dirs = [\"Merged Same Speaker\"] + audio_dirs\n",
    "                else:\n",
    "                    audio_dirs = [\"Merged Multi Speaker\"] + audio_dirs                    \n",
    "                \n",
    "                # cleanup the break point between clips\n",
    "                if explicit_merge:\n",
    "                    merged_quote = prev_quote+'#'+quote\n",
    "                else:\n",
    "                    if time_between_clips < 0.08:\n",
    "                        prev_quote = prev_quote[:-1]+\",\" if prev_quote[-1] == \".\" else prev_quote\n",
    "                        merged_quote = prev_quote+' '+quote\n",
    "                    elif time_between_clips < 0.3:\n",
    "                        merged_quote = prev_quote+' '+quote\n",
    "                    elif silent_time_between_clips > 0.4:\n",
    "                        prev_quote = prev_quote+\"..\" if prev_quote[-1] == \".\" else prev_quote # \"Sentence. Yes?\" -> \"Sentence... Yes?\" if pause has no breathing and last clip ends with \".\"\n",
    "                        merged_quote = prev_quote+' '+quote\n",
    "                    else:\n",
    "                        merged_quote = prev_quote+' '+quote\n",
    "                \n",
    "                # ensure merged quote isn't too long for saving.\n",
    "                while len(merged_quote) > MAX_FILENAME_LENGTH:\n",
    "                    merged_quote = \" \".join(merged_quote.split(\" \")[:-1])+merged_quote[-1] # cut of the last word\n",
    "                \n",
    "                filename = f\"{'_'.join(prev_time_stamp)}_{' '.join(uniqueElems([prev_voice, voice]))}_{' '.join(uniqueElems(prev_emotions+emotions))}_{noise_level}_{merged_quote}.wav\"\n",
    "                output_folder = os.path.join(working_dir, 'Sliced', *audio_dirs)\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                librosa.output.write_wav(output_path, clipped_audio, SAMPLE_RATE)\n",
    "            \n",
    "            if False: # normal sliced dialogue\n",
    "                clipped_audio = audio[label_start_sample:label_stop_sample]\n",
    "                assert len(clipped_audio), f\"LABEL: {label}\\nFILE: {label_path}\\ndid not process correctly. Output audio has 0 length.\"\n",
    "                \n",
    "                audio_dirs = [\"Sliced\"] + audio_dirs\n",
    "                \n",
    "                filename = f\"{'_'.join(prev_time_stamp)}_{' '.join(uniqueElems([prev_voice, voice]))}_{' '.join(uniqueElems(prev_emotions+emotions))}_{noise_level}_{quote}.wav\"\n",
    "                output_folder = os.path.join(working_dir, 'Sliced', *audio_dirs)\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                librosa.output.write_wav(output_path, clipped_audio, SAMPLE_RATE)\n",
    "            \n",
    "            # --- DO STUFF ---\n",
    "            prev_label = label\n",
    "\n",
    "\n",
    "def test_audio_files(directory):\n",
    "    \"\"\"\n",
    "    For different audio files, test whether they trim correctly.\n",
    "    \"\"\"\n",
    "    paths = glob(directory+\"/*.wav\")\n",
    "    for audio_path in paths:\n",
    "        audio, _ = librosa.core.load(audio_path, sr=SAMPLE_RATE)\n",
    "        def return_ref(input):\n",
    "            return 0.0000250 # 0.0000020 for trimming silence but leaving breathing in.\n",
    "                             # 0.0000250 for trimming silence and also quiet breathing.\n",
    "        index = librosa.effects.trim(audio, top_db=0, frame_length=int(SAMPLE_RATE*0.100), hop_length=int(SAMPLE_RATE*0.0125), ref=return_ref)[1]   \n",
    "        print(\"file:\", os.path.basename(audio_path),\"\\t\", round(index[0]/SAMPLE_RATE,2), \"\\t\", round((len(audio)-index[1])/SAMPLE_RATE,2), \"\\tduration:\", round((index[1]-index[0])/SAMPLE_RATE,2), \"\\toriginal_duration:\\t\", round(len(audio)/SAMPLE_RATE,2), \"\\tPercent:\",round((index[1]-index[0])/len(audio),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree, remove_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADS = 6\n",
    "AUDIO_DEPTH = 2 # target Audio, eg. 16 bit audio = 2 (bytes)\n",
    "SAMPLE_RATE = 48000\n",
    "\n",
    "DIRECTORY_GLOBAL = r\"D:\\Sound Sample\\Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess_directory_wavs(func, directory, threads=1):\n",
    "    file_paths = glob(directory+r\"/**/*.wav\", recursive=True)\n",
    "    print(func(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter_wavs_multiprocess(file_paths_arr, cutoff_freq, strength):\n",
    "    import soundfile as sf\n",
    "    import scipy\n",
    "    from scipy import signal\n",
    "    \n",
    "    prev_sr = 0\n",
    "    for file_path in tqdm(file_paths_arr, smoothing=0.0): # recursive directory search\n",
    "            audio, sample_rate = sf.read(file_path) # load audio to RAM\n",
    "            if cutoff_freq*2 < sample_rate:\n",
    "                if sample_rate != prev_sr:\n",
    "                        sos = signal.butter(strength, cutoff_freq, 'lp', fs=sample_rate, output='sos') # calcuate filter somethings\n",
    "                        prev_sr = sample_rate\n",
    "                filtered_audio = signal.sosfilt(sos, audio) # apply filter\n",
    "                sf.write(file_path, filtered_audio, sample_rate) # write back to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▎                                                                   | 19/66 [00:00<00:00, 182.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Global 150Hz highpass filter to remove microphone noise/quiet electical humming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 184.33it/s]\n",
      "  6%|█████▉                                                                                           | 4/66 [00:00<00:02, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Running Global 40Hz highpass filter to remove microphone noise/quiet electical humming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 24.67it/s]\n",
      " 21%|████████████████████▏                                                                          | 14/66 [00:00<00:00, 135.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Running Global 16000Hz lowpass filter to remove microphone noise/quiet electical humming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 110.82it/s]\n",
      "  6%|█████▉                                                                                           | 4/66 [00:00<00:01, 32.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Running Global 20000Hz lowpass filter to remove microphone noise/quiet electical humming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------Main block--------------\n",
    "if __name__ == '__main__':\n",
    "    metadata = {}\n",
    "    \n",
    "    remove_tree(DIRECTORY_GLOBAL)\n",
    "    copy_tree(r\"D:\\Sound Sample\\Original\", DIRECTORY_GLOBAL)\n",
    "    \n",
    "    freq = 150\n",
    "    strength = 4\n",
    "    print(f\"Running Global {freq}Hz highpass filter to remove microphone noise/quiet electical humming.\")\n",
    "    def func(array):\n",
    "        high_pass_filter_wavs_multiprocess(array, freq, strength)\n",
    "    multiprocess_directory_wavs(func, DIRECTORY_GLOBAL, threads=1)\n",
    "    \n",
    "    freq = 40\n",
    "    strength = 60\n",
    "    print(f\"Running Global {freq}Hz highpass filter to remove microphone noise/quiet electical humming.\")\n",
    "    def func(array):\n",
    "        high_pass_filter_wavs_multiprocess(array, freq, strength)\n",
    "    multiprocess_directory_wavs(func, DIRECTORY_GLOBAL, threads=1)\n",
    "    \n",
    "    freq = 16000\n",
    "    strength = 10\n",
    "    print(f\"Running Global {freq}Hz lowpass filter to remove microphone noise/quiet electical humming.\")\n",
    "    def func(array):\n",
    "        low_pass_filter_wavs_multiprocess(array, freq, strength)\n",
    "    multiprocess_directory_wavs(func, DIRECTORY_GLOBAL, threads=1)\n",
    "    \n",
    "    freq = 20000\n",
    "    strength = 60\n",
    "    print(f\"Running Global {freq}Hz lowpass filter to remove microphone noise/quiet electical humming.\")\n",
    "    def func(array):\n",
    "        low_pass_filter_wavs_multiprocess(array, freq, strength)\n",
    "    multiprocess_directory_wavs(func, DIRECTORY_GLOBAL, threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random; training_percent = 0.5\n",
    "with open(\"train.txt\",\"w\") as train, open(\"val.txt\",\"w\") as val:\n",
    "    [train.write(f\"{x}\\n\") if random.random() < training_percent else val.write(f\"{x}\\n\") for x in open(\"training_lines_here.txt\",'r').read().split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('import random; training_percent = 0.5\\nwith open(\"train.txt\",\"w\") as train, open(\"val.txt\",\"w\") as val:\\n\\t[train.write(f\"{x}\\\\n\") if random.random() < training_percent else val.write(f\"{x}\\\\n\") for x in open(\"training_lines_here.txt\",'r').read().split(\"\\\\n\")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisdict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07 s ± 44.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "string = \"\"\n",
    "for i in range(120000):\n",
    "    string = string + f\"EXTRA STUFF EXTRA STUFF EXTRA STUFF EXTRA STUFF. {i} + {i*100}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.3 ms ± 1.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "arr = []\n",
    "for i in range(120000):\n",
    "    arr.append(f\"EXTRA STUFF EXTRA STUFF EXTRA STUFF EXTRA STUFF. {i} + {i*100}\")\n",
    "arr = \"\\n\".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "arr = list()\n",
    "for i in range(120000):\n",
    "    arr.append(f\"EXTRA STUFF EXTRA STUFF EXTRA STUFF EXTRA STUFF. {i} + {i*100}\")\n",
    "arr = \"\\n\".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.8 ms ± 2.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "arr = list()\n",
    "for i in range(120000):\n",
    "    arr.append(f\"EXTRA STUFF EXTRA STUFF EXTRA STUFF EXTRA STUFF. {i} + {i*100}\")\n",
    "arr = \"\\n\".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.39 µs ± 251 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "string = \"\"\n",
    "end_chars = \"$\"\n",
    "for i in range(12):\n",
    "    string=string + (\"WORD \" + end_chars).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 µs ± 231 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "string = \"\"\n",
    "end_chars = \"$\"\n",
    "for i in range(12):\n",
    "    string+=(\"WORD \" + end_chars).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.81 µs ± 188 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "arr = []\n",
    "end_chars = \"$\"\n",
    "for i in range(12):\n",
    "    arr.append((\"WORD \" +end_chars).strip())\n",
    "arr = \" \".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2 µs ± 224 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\" \".join([f\"WORD {x}\" for x in range(12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15470, 48836, 17056, 54425, 46086])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randint(0,65535,(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv1d(1,1,3, padding=1, padding_mode='reflect')\n",
    "conv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(10)[None, None, :].float()\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5703,  2.6898,  5.3838,  8.0778, 10.7718, 13.4658, 16.1598,\n",
      "          18.8539, 21.5479, 21.7562]]])\n",
      "torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(conv(input), conv(input).shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    |0         |0.0       \n",
      "1    |768       |1.28      \n",
      "2    |1536      |2.56      \n",
      "3    |2304      |3.84      \n",
      "4    |3072      |5.12      \n",
      "5    |3840      |6.4       \n",
      "6    |4608      |7.68      \n",
      "7    |5376      |8.96      \n",
      "8    |6144      |10.24     \n",
      "9    |6912      |11.52     \n",
      "10   |7680      |12.8      \n",
      "11   |8448      |14.08     \n",
      "12   |9216      |15.36     \n",
      "13   |9984      |16.64     \n",
      "14   |10752     |17.92     \n",
      "15   |11520     |19.2      \n",
      "16   |12288     |20.48     \n",
      "17   |13056     |21.76     \n",
      "18   |13824     |23.04     \n",
      "19   |14592     |24.32     \n",
      "20   |15360     |25.6      \n",
      "21   |16128     |26.88     \n",
      "22   |16896     |28.16     \n",
      "23   |17664     |29.44     \n",
      "24   |18432     |30.72     \n",
      "25   |19200     |32.0      \n",
      "26   |19968     |33.28     \n",
      "27   |20736     |34.56     \n",
      "28   |21504     |35.84     \n",
      "29   |22272     |37.12     \n",
      "30   |23040     |38.4      \n",
      "31   |23808     |39.68     \n",
      "32   |24576     |40.96     \n",
      "33   |25344     |42.24     \n",
      "34   |26112     |43.52     \n",
      "35   |26880     |44.8      \n",
      "36   |27648     |46.08     \n",
      "37   |28416     |47.36     \n",
      "38   |29184     |48.64     \n",
      "39   |29952     |49.92     \n",
      "40   |30720     |51.2      \n",
      "41   |31488     |52.48     \n",
      "42   |32256     |53.76     \n",
      "43   |33024     |55.04     \n",
      "44   |33792     |56.32     \n",
      "45   |34560     |57.6      \n",
      "46   |35328     |58.88     \n",
      "47   |36096     |60.16     \n",
      "48   |36864     |61.44     \n",
      "49   |37632     |62.72     \n",
      "50   |38400     |64.0      \n",
      "51   |39168     |65.28     \n",
      "52   |39936     |66.56     \n",
      "53   |40704     |67.84     \n",
      "54   |41472     |69.12     \n",
      "55   |42240     |70.4      \n",
      "56   |43008     |71.68     \n",
      "57   |43776     |72.96     \n",
      "58   |44544     |74.24     \n",
      "59   |45312     |75.52     \n"
     ]
    }
   ],
   "source": [
    "_=[print(f\"{i:<5}|{((2**8)*3*i):<10}|{((2**8)*3*i)/600:<10}\") for i in range(60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time|n_group|length|\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6.25|      2|300.0 |Whole Number\n",
      "3.12|      4|150.0 |Whole Number\n",
      "2.08|      6|100.0 |Whole Number\n",
      "1.56|      8|75.0  |Whole Number\n",
      "1.25|     10|60.0  |Whole Number\n",
      "1.04|     12|50.0  |Whole Number\n",
      "0.62|     20|30.0  |Whole Number\n",
      "0.52|     24|25.0  |Whole Number\n",
      "0.42|     30|20.0  |Whole Number\n",
      "0.31|     40|15.0  |Whole Number\n",
      "0.25|     50|12.0  |Whole Number\n",
      "0.21|     60|10.0  |Whole Number\n",
      "0.12|    100|6.0   |Whole Number\n",
      "0.1 |    120|5.0   |Whole Number\n",
      "0.08|    150|4.0   |Whole Number\n",
      "0.06|    200|3.0   |Whole Number\n",
      "0.04|    300|2.0   |Whole Number\n",
      "0.02|    600|1.0   |Whole Number\n"
     ]
    }
   ],
   "source": [
    "sr = 48000\n",
    "hop_length = 600\n",
    "print(\"time|n_group|length|\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "_=[print(f\"{round(1000*x/sr,2):<4}|{x:7}|{hop_length/x:<6}|{'Whole Number' if hop_length//x == hop_length/x else ''}\") for x in range(2,hop_length+2,2) if hop_length//x == hop_length/x]\n",
    " # n_group | hop_size/n_group | whole_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
